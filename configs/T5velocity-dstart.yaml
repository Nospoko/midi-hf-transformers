train:
  num_epochs: 5
  accum_iter: 10
  batch_size: 8
  base_lr: 3e-5
  finetune: True
  warmup: 4000


pretrained_checkpoint: midi-T5-2023-11-15-17-18.pt
model_name: T5
dataset_name: 'roszcz/maestro-v1-sustain'
target: velocity
seed: 26
time_bins: 100

overfit: False

tokens_per_note: "single"
time_quantization_method: dstart
dataset:
  sequence_len: 128
  sequence_step: 42

  quantization:
    dstart: 5
    duration: 5
    velocity: 3

device: "cuda:0"

log: True
log_frequency: 10
run_name: midi-T5-${now:%Y-%m-%d-%H-%M}
project: "midi-hf-transformer"

pre_defined_model: null

model:
  d_model: 512
  d_kv: 64
  d_ff: 2048
  num_layers: 6
  num_decoder_layers: None
  num_heads: 8
