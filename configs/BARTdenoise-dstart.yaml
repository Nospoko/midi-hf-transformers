train:
  num_epochs: 5
  accum_iter: 5
  batch_size: 2
  base_lr: 3e-5
  warmup: 4000
  finetune: False

model_name: BART
dataset_name: 'roszcz/maestro-v1-sustain'
target: denoise
seed: 26

overfit: False

tokens_per_note: single
time_quantization_method: dstart
masking_probability: 0.3
mask: tokens

encoder: velocity
time_bins: 100

dataset:
  sequence_len: 128
  sequence_step: 42

  quantization:
    dstart: 8
    duration: 8
    velocity: 3

device: "cuda:0"

log: True
log_frequency: 10
run_name: midi-bart-${now:%Y-%m-%d-%H-%M}
project: "midi-bart"

pre_defined_model: null
model:
  encoder_layers: 6
  encoder_ffn_dim: 2048
  encoder_attention_heads: 8
  decoder_layers: 6
  decoder_ffn_dim: 2048
  decoder_attention_heads: 8
  d_model: 512
