train:
  num_epochs: 5
  accum_iter: 5
  batch_size: 2
  base_lr: 3e-5
  warmup: 4000
  finetune: False

model_name: T5
dataset_name: 'roszcz/maestro-v1-sustain'
target: denoise
seed: 26

overfit: False

tokens_per_note: single
time_quantization_method: dstart
masking_probability: 0.2
mask: tokens

encoder: velocity
time_bins: 100

dataset:
  sequence_len: 128
  sequence_step: 42

  quantization:
    dstart: 5
    duration: 5
    velocity: 3

device: "cuda:0"

log: True
log_frequency: 10
run_name: midi-T5-${now:%Y-%m-%d-%H-%M}
project: "midi-hf-transformer"

model:
  d_model: 512
  d_kv: 64
  d_ff: 2048
  num_layers: 6
  num_heads: 8
